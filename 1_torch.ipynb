{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_torch.ipynb","provenance":[],"collapsed_sections":["4i4ixbtRvWfK","2PP_LZKUv-Pw","N0U99w0Z1J1k","gBMqmb1urXJn","ZYC109fc1MVw","UHPi91Ak1QLy","ICQ3rQM41S61","SGCmjmio1UEl","V9To0x2l1lvf","EXDdDbNVSNqe","7a2-YxEI2edt","rKg8v0ai2eZw","0-9wHoHp2eWF","q7lrYxaz2eSK","y1Cg_OlH6dxJ","2R_wSEVL3fec","S7T8rL_k3fi8","nK5V_gIEv-Dp","nkHr3Fc_v96R"],"toc_visible":true,"mount_file_id":"1PYV2XUARRkZHp4KWfRIJaGJB7BFPlS3e","authorship_tag":"ABX9TyMezNkMaO6BFxcsPIEbWKSD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"d8w3wM_hvRFB"},"source":["# torch"]},{"cell_type":"code","metadata":{"id":"1rH5VeTWwndj","executionInfo":{"status":"ok","timestamp":1632539328881,"user_tz":-540,"elapsed":4283,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}}},"source":["import torch\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4i4ixbtRvWfK"},"source":["## 1. Tensors"]},{"cell_type":"markdown","metadata":{"id":"T9lXZe9awdcV"},"source":["### is_tensor"]},{"cell_type":"code","metadata":{"id":"bImrT5hVvNDy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632419138204,"user_tz":-540,"elapsed":318,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"6e0422da-c43a-4747-9cc0-5359782e2a65"},"source":["x = torch.tensor([1, 2, 3])\n","print(torch.is_tensor(x))\n","\n","y = np.array([1, 2, 3])\n","print(torch.is_tensor(y))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"markdown","metadata":{"id":"XJdgEYB7w3IP"},"source":["### is_floating_point"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lf_CHoGxw2zr","executionInfo":{"status":"ok","timestamp":1632419492920,"user_tz":-540,"elapsed":338,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"e85afbf1-c10d-4351-823b-253016fff2ed"},"source":["x = torch.DoubleTensor([1, 2, 3])\n","y = torch.LongTensor([1, 2, 3])\n","\n","print(torch.is_floating_point(x))\n","print(torch.is_floating_point(y))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"markdown","metadata":{"id":"aIJdoHGlyOm2"},"source":["### is_nonzero"]},{"cell_type":"markdown","metadata":{"id":"u3hJOFXBypzv"},"source":["Returns True if the input is a **single element tensor** which is not equal to zero after type conversions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkqyapNDyTgk","executionInfo":{"status":"ok","timestamp":1632419703254,"user_tz":-540,"elapsed":353,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"7ba4d2ff-bae9-489f-c8b2-dbd3f4ef864a"},"source":["x = torch.randn((1, 1))\n","\n","print(torch.is_nonzero(x))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"markdown","metadata":{"id":"q1Fggg-VzIdd"},"source":["### numel"]},{"cell_type":"markdown","metadata":{"id":"ARLWM5FyzWDo"},"source":["Returns **the total number of elements** in the input tensor."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQ8QUzaEzJ81","executionInfo":{"status":"ok","timestamp":1632419780773,"user_tz":-540,"elapsed":387,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"da49ba9a-0053-4bc8-c6c9-6b0164ea0127"},"source":["x = torch.randn((2, 2))\n","\n","print(torch.numel(x))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}]},{"cell_type":"markdown","metadata":{"id":"2PP_LZKUv-Pw"},"source":["## 2. Creation Ops ⭐️⭐️⭐️"]},{"cell_type":"markdown","metadata":{"id":"N0U99w0Z1J1k"},"source":["### tensor\n","- torch.tensor(data, dtype, device, requires_grad, pin_memory)\n","- torch.tensor() always copies data -> 메모리 공유 X\n","    - 메모리 낭비가 걱정된다면 -> new_tensor = old_tensor.detach()\n","    - 메모리 낭비가 걱정된다면 -> new_tensor = old_ndarray.as_tensor()\n","- torch.tensor()와 Tensor.clone().detach()는 역할이 같다\n","- clone().detach()를 권장하는 이유는\n","> Tensor.clone().detach() makes it very clear what happenes to the Tensor. You first allocate new memory for it then detach it from the autograd graph from the original one."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cer1jYFM8nNa","executionInfo":{"status":"ok","timestamp":1632456088003,"user_tz":-540,"elapsed":342,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"761a9107-7cf6-4c09-bd5b-4b157b9eacb3"},"source":["x = torch.rand(3, requires_grad=True)\n","\n","print(x.requires_grad)\n","\n","y = torch.tensor(x)\n","z = x.clone().detach()\n","\n","print(y.requires_grad)\n","print(z.requires_grad)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n","False\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]}]},{"cell_type":"markdown","metadata":{"id":"gBMqmb1urXJn"},"source":["### IntTensor, LongTensor, FloatTensor(=Tensor), DoubleTensor"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzhC0M0W_LHx","executionInfo":{"status":"ok","timestamp":1632456779080,"user_tz":-540,"elapsed":366,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"2007077d-6a50-405d-88a8-fa3dcd37ce04"},"source":["l = [[1, 2], [3, 4]]\n","a = np.array([[1, 2], [3, 4]])\n","\n","t1 = torch.LongTensor(l)\n","t2 = torch.LongTensor(a)\n","\n","t3 = torch.FloatTensor(l)\n","t4 = torch.FloatTensor(a)\n","\n","print(t1, t2, t3, t4, '\\n')\n","\n","t1[0][0] = 10\n","t2[0][0] = 100\n","print(t1, '\\n')\n","print(t2, '\\n')\n","print(l, '\\n')\n","print(a, '\\n')\n","# list와는 메모리 공유 안하고, ndarray와는 메모리 공유하는 것인가?"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]]) tensor([[1, 2],\n","        [3, 4]]) tensor([[1., 2.],\n","        [3., 4.]]) tensor([[1., 2.],\n","        [3., 4.]]) \n","\n","tensor([[10,  2],\n","        [ 3,  4]]) \n","\n","tensor([[100,   2],\n","        [  3,   4]]) \n","\n","[[1, 2], [3, 4]] \n","\n","[[100   2]\n"," [  3   4]] \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZYC109fc1MVw"},"source":["### as_tensor\n","- torch.as_tensor(data, dtype, device)\n","- convert the data into a torch.Tensor\n","- share same memory\n","- not only numpy but list, ..\n","- slower than from_numpy\n","- https://discuss.pytorch.org/t/from-numpy-vs-as-tensor/79932https://discuss.pytorch.org/t/from-numpy-vs-as-tensor/79932\n","- list나 ndarray, tensor와 같은 객체를 tensor객체로 변환시켜준다\n","- 만약 tensor -> tensor인데 dtype, required_grad 모두 같으면 메모리 공유 -> no copy will be performed\n","- list, ndarray -> tensor인데 dtype 같으면 메모리 공유 -> no copy will be performed\n","- dtype 바뀌거나, requires_grad 바뀌면 메모리 공유 X -> copy will be performed\n","- (메모리 공유하는지는 a is b == True 로 확인하면 되는 것 맞나?) -> 맞다\n","- https://stackoverflow.com/questions/5445080/compare-if-two-variables-reference-the-same-object-in-python"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ayPNNbQF3tS-","executionInfo":{"status":"ok","timestamp":1632468607774,"user_tz":-540,"elapsed":363,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"939834c4-7c98-4015-c2b9-bd04acb732b3"},"source":["a = np.array([1, 2, 3])\n","\n","t = torch.as_tensor(a)\n","\n","t[0] = -1\n","\n","print(a, t, sep='\\n')\n","print(a is t)\n","print(id(a), id(b))\n","\n","# t를 바꾸니까 a도 함께 바뀌는 것을 봤을 때는 메모리를 공유하는 것 같은데 memory주소는 다르다\n","# as_tensor는 메모리를 공유한다고 알고있는데 무엇이 문제인가"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[-1  2  3]\n","tensor([-1,  2,  3])\n","False\n","139685700991536 139685701344624\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_YXJ8ldo8qj","executionInfo":{"status":"ok","timestamp":1632454485180,"user_tz":-540,"elapsed":326,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"3fd86df1-d3c5-4520-9cef-c1229bf3a6dd"},"source":["a = torch.tensor([1, 2, 3])\n","\n","t = torch.as_tensor(a)\n","\n","t[0] = -1\n","\n","# print(a.is_leaf, t.is_leaf)\n","\n","print(a is t)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bi3yuhF4pOcM","executionInfo":{"status":"ok","timestamp":1632456183541,"user_tz":-540,"elapsed":417,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"fd2bde55-6dd6-4797-8622-d72ad4cf3afd"},"source":["a = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=True)\n","\n","t = torch.as_tensor(a)\n","\n","# print(a.is_leaf, t.is_leaf)\n","\n","print(a is t)\n","try:\n","    a[0] = -1\n","except:\n","    # https://discuss.pytorch.org/t/leaf-variable-was-used-in-an-inplace-operation/308\n","    # requires_grad=True인 leaf variables에는 in-place operation 사용이 안된다\n","    print(\"PyTorch doesn’t allow in-place operations on leaf variables that have requires_grad=True (such as parameters of your model) \\nbecause the developers could not decide how such an operation should behave. \\nIf you want the operation to be differentiable, you can work around the limitation by cloning the leaf variable (or use a non-inplace version of the operator).\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","PyTorch doesn’t allow in-place operations on leaf variables that have requires_grad=True (such as parameters of your model) \n","because the developers could not decide how such an operation should behave. \n","If you want the operation to be differentiable, you can work around the limitation by cloning the leaf variable (or use a non-inplace version of the operator).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4w03fTaFzq-B","executionInfo":{"status":"ok","timestamp":1632453470813,"user_tz":-540,"elapsed":337,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"08d8ebc3-5bed-4410-849a-67e398649407"},"source":["a = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=True)\n","\n","t = torch.as_tensor(a, dtype=torch.long)\n","\n","print(a is t)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","metadata":{"id":"4f17Q0m5qkrR"},"source":["a = np.array([1, 2, 3, 4])\n","\n","b = torch.Tensor(a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHPi91Ak1QLy"},"source":["### from_numpy\n","- share same memory\n","- only numpy -> faster than as_tensor"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4KpIdyAsA6sf","executionInfo":{"status":"ok","timestamp":1632456964213,"user_tz":-540,"elapsed":382,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"7544212c-4bda-496a-f730-d5dc5a6c495f"},"source":["a = np.array([[1, 2], [3, 4]])\n","\n","t = torch.from_numpy(a)\n","\n","t[0][0] = 100\n","print(a)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[100   2]\n"," [  3   4]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ICQ3rQM41S61"},"source":["### zeros, zeros_like, ones, ones_like\n","- torch.zeros(size, dtype, device, requirers_grad) (size는 sequence of intergers)\n","- torch.zeros_like(input, dtype, device, requires_grad)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0n-0yVxBejR","executionInfo":{"status":"ok","timestamp":1632457083002,"user_tz":-540,"elapsed":395,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"c6eca9b3-4c17-4cfb-a440-681168d8f30a"},"source":["torch.zeros(2, 3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tf6_ojoCCcej","executionInfo":{"status":"ok","timestamp":1632457708437,"user_tz":-540,"elapsed":393,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"1e512646-cdba-4510-9e99-fa875217d3c5"},"source":["x = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n","y = torch.as_tensor(x)\n","try:\n","    t = torch.zeros_like(x)\n","except TypeError:\n","    print(\"'input' must be 'Tensor'\")\n","    print(\"if you want to use ndarray as input -> torch.zeros(ndarray.shape)\")\n","    t = torch.zeros_like(y)\n","    t = torch.zeros(x.shape)\n","\n","t"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'input' must be 'Tensor'\n","if you want to use ndarray as input -> torch.zeros(ndarray.shape)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0., 0.],\n","        [0., 0., 0., 0.]])"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","metadata":{"id":"SGCmjmio1UEl"},"source":["### arange, range, linspace\n","- torch.arange(start, end, step, dtype, device, requires_grad)\n","- torch.range(start, end, step, dtype, device, requires_grad) -> 사용x\n","- torch.linspace(start, end, steps, dtype, device, requires_grad)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lmCV4ukEMQe","executionInfo":{"status":"ok","timestamp":1632457811352,"user_tz":-540,"elapsed":337,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"95a731fd-5026-49a6-8fbc-9bd2c9a21e85"},"source":["print(torch.arange(5))\n","print(torch.arange(1, 4))\n","print(torch.arange(0, 2.5, 0.5))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1, 2, 3, 4])\n","tensor([1, 2, 3])\n","tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5l-dwoRjEusZ","executionInfo":{"status":"ok","timestamp":1632458004664,"user_tz":-540,"elapsed":334,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"c236dc5b-dfaf-47e3-e0ee-c212c5cda0e3"},"source":["# 얘는 이름은 파이썬의 range와 같은데 끝을 포함한다는 점에서 다르다 -> 사용 지양 -> 파이썬 range와 유사한 torch.arange 권장\n","print(torch.range(1, 4))\n","print(torch.range(1, 4, 0.5))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 4.])\n","tensor([1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxWZFH-oFT4Q","executionInfo":{"status":"ok","timestamp":1632458159780,"user_tz":-540,"elapsed":315,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"c159f4e0-e443-4b57-b16e-6b881af0d57f"},"source":["print(torch.linspace(3, 10, 5))\n","print(torch.linspace(-10, 10, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])\n","tensor([-10.])\n"]}]},{"cell_type":"markdown","metadata":{"id":"V9To0x2l1lvf"},"source":["### empty, empty_like, full, full_like\n","- torch.empty(size, dtype, device, requires_grad, pin_memory)\n","    - uninitialized data -> not empty\n","    - dtype지정 안하면 거의 0에 가까운 값\n","    - size는 sequence of integers\n","\n","- torch.full(size, fill_value, dtype, device, requires_grad)\n","    - fill_value(Scalar)로 채워진 tensor 리턴\n","    - size는 list, tuple,  or torch.Size"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-Cv020XObGw","executionInfo":{"status":"ok","timestamp":1632461063711,"user_tz":-540,"elapsed":408,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"9dba28bc-c428-44bd-abee-cdb789d8185d"},"source":["a = torch.empty(2, 3, dtype=torch.int32)\n","\n","# sequence of integers이지만 list, tuple같은 것도 된다.\n","b = torch.empty((2, 3))\n","c = torch.empty([2, 3])\n","\n","print(a, b, c, sep='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1070479680,      21984,        114],\n","        [        99,        104,         46]], dtype=torch.int32)\n","tensor([[1.6111e+00, 3.0806e-41, 3.3631e-44],\n","        [0.0000e+00,        nan, 0.0000e+00]])\n","tensor([[1.6111e+00, 3.0806e-41, 1.5975e-43],\n","        [1.3873e-43, 1.4574e-43, 6.4460e-44]])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nukoOOjfPAs7","executionInfo":{"status":"ok","timestamp":1632460924086,"user_tz":-540,"elapsed":456,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"b7ee49b0-8781-47b6-c9c6-4d10018a6152"},"source":["torch.full((2, 3), 100)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[100, 100, 100],\n","        [100, 100, 100]])"]},"metadata":{},"execution_count":103}]},{"cell_type":"markdown","metadata":{"id":"EXDdDbNVSNqe"},"source":["### ❓ computational graph (Autograd)\n","https://tutorials.pytorch.kr/beginner/blitz/autograd_tutorial.html"]},{"cell_type":"markdown","metadata":{"id":"eDJ6RD3DMvFV"},"source":["#### Background"]},{"cell_type":"markdown","metadata":{"id":"nvakEB25NY6J"},"source":["신경망 학습은 크게 두 단계로 나뉘어집니다.\n","- 순전파: forward propagation을 통해prediction을 구하고 이를 이용해 loss 계산\n","- 역전파: back prop을 통해 gradients를 구하고 이를 이용해 parameter들을 adjust"]},{"cell_type":"code","metadata":{"id":"9k-_XfWYO5eW"},"source":["# forward prop\n","# prediction = model(data)\n","\n","# backward prop\n","# loss.backward()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0BGL0a2zPNhn"},"source":["#### Autograd"]},{"cell_type":"markdown","metadata":{"id":"NpPE_Yu0PqTv"},"source":["- 텐서에 requires_grad=True를 적용하면 이는 autograd가 이 tensor의 모든 연산들을 추적하도록 합니다\n","- loss가 계산되고 loss.backward()를 호출하면 autograd는 gradient를 계산하고 이를 텐서의 .grad 속성(attribute)에 저장합니다\n","- autograd는 실행 시점에 정의되는(define-by-run) 프레임워크입니다"]},{"cell_type":"markdown","metadata":{"id":"RS1I6RvIxhgi"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"moq1WwtPQ7L0"},"source":["#### Computation Graph (DAG)"]},{"cell_type":"markdown","metadata":{"id":"5RoV5HGZQ-Ba"},"source":["- Autograd는 텐서의 모든 연산들의 기록을 [Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)객체로 구성된 DAG(방향성 비순환 그래프)에 저장합니다.\n","    - Pytorch의 computation graph를 그릴 때 각 노드에 실제로 들어가는 것은 tensor의 grad_fn\n","    - Function객체는 forward, backward 메서드를 갖는다\n","    - 이렇게 객체로 관리하는 이유는 backward 메서드에서 forward 에서의 input을 사용하므로 공유하기 위해\n","    - https://hwijeen.github.io/2019-01-30/Pytorch-autograd/\n","- chain rule을 효율적으로 계산하도록 해주는 그래프 형태\n","- 여기서 입력 텐서는 leaf, 출력 텐서는 root입니다.\n","- .backward()가 호출되면\n","    - 각 .grad_fn(미분함수)으로부터 gradient 계산\n","    - 각 텐서의 .grad 속성에 계산 결과 누적\n","    - chain rule이용해서 leaf까지 back propagation\n","- Pytorch의 DAG는 dynamic -> forward prop마다(iter) 새로운 그래프 생성\n","- requires_grad=False를 하면 텐서에 대한 연산 추적 그만둔다(DAG에서 gradient 계산 제외된다)"]},{"cell_type":"markdown","metadata":{"id":"y-26kobIy-Ur"},"source":["### ❓ leaf variable"]},{"cell_type":"markdown","metadata":{"id":"hWJ7IABqzT6s"},"source":["- DAG 그래프에서 어떤 연산이 적용되지 않은 텐서를 leaf node라고 합니다\n","    - leaf node의 grad_fn은 None입니다.\n","- leaf node는 DAG 안에서 autograd되어야 하므로 in-place 연산이 허용되지 않습니다\n","- 따라서 w를 업데이트 할 때 w -= lr * w.grad로 하면 안되고 w.data -= lr * w.grad 해야합니다.\n","- https://m.blog.naver.com/myincizor/221691061964#"]},{"cell_type":"markdown","metadata":{"id":"f7rgJ4i0v-Ms"},"source":["## 3. Indexing, Slicing, Joining, Mutating Ops ⭐️⭐️⭐️"]},{"cell_type":"markdown","metadata":{"id":"7a2-YxEI2edt"},"source":["### cat\n","- torch.cat(tensors, dim)\n","- concatenating되는 dim 제외한 나머지 shape은 같아야 함"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmcsRp-yZjys","executionInfo":{"status":"ok","timestamp":1632497257511,"user_tz":-540,"elapsed":412,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"24c16949-4580-4082-bed6-f8fa25c73875"},"source":["x1 = torch.randn(2, 3)\n","x2 = torch.randn(2, 1)\n","\n","# 괄호로 묶어줘야함\n","y = torch.cat((x1, x2), dim=1)\n","print(y.shape)\n","print(x1, x2, y, sep='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 4])\n","tensor([[-0.2995, -1.1762, -1.0677],\n","        [ 1.2605,  0.4792, -1.9207]])\n","tensor([[0.0565],\n","        [0.5285]])\n","tensor([[-0.2995, -1.1762, -1.0677,  0.0565],\n","        [ 1.2605,  0.4792, -1.9207,  0.5285]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"rKg8v0ai2eZw"},"source":["### chunk\n","- torch.chunk(input, chunks, dim) -> Tuple of Tensors\n","- chunks 값만큼 덩어리 개수가 생긴다\n","- 정확히 나누어지지 않으면 기대했던 결과와 다를 가능성 높다\n","- 사용 빈도 낮을 것 같다"]},{"cell_type":"code","metadata":{"id":"VIsqPPCRbAsG"},"source":["x = torch.randn(3, 20)\n","\n","chunked_tensors = torch.chunk(x, 8, dim=1)\n","print(len(chunked_tensors))\n","print(chunked_tensors)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-9wHoHp2eWF"},"source":["### stack, vstack, hstack, dstack\n","#### stack\n","- torch.stack(tensors, dim)\n","- concatenates a sequence of tensors along **new dimension**👈\n","- All tensors need to be of the **same size**👈\n","- dim range는 [-(Tensor.dim()+1), Tensor.dim()]이다\n","\n","#### vstack\n","- torch.vstack(tensors)\n","- row방향으로 쌓는다, 세로 방향으로 쌓는다, dim=0으로 쌓는다\n","- (2, 3), (2, 3) -> (4, 3)\n","- (1, 2, 3), (1, 2, 3) -> (2, 2, 3)\n","- (1, 2, 3, 4), (1, 2, 3, 4) -> (2, 2, 3, 4)\n","\n","#### hstack\n","- torch.hstack(tensors)\n","- col방향으로 쌓는다, 가로 방향으로 쌓는다, dim=1로 쌓는다\n","- (2, 3), (2, 3) -> (2, 6)\n","- (1, 2, 3), (1, 2, 3) -> (1, 4, 3)\n","- (1, 2, 3, 4), (1, 2, 3, 4) -> (1, 4, 3, 4)\n","\n","#### dstack\n","- torch.hstack(tensors)\n","- depth 방향으로 쌓는다, dim=2로 쌓는다\n","- (2, 3), (2, 3) -> (2, 3, 2)\n","- (1, 2, 3), (1, 2, 3) -> (1, 2, 6)\n","- (1, 2, 3, 4), (1, 2, 3, 4) -> (1, 2, 6, 4)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WmI21cnUd1KQ","executionInfo":{"status":"ok","timestamp":1632499386847,"user_tz":-540,"elapsed":374,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"bca263db-0120-48ad-faf4-ec01af4340f4"},"source":["# stack\n","x1 = torch.randn(1, 2)\n","x2 = torch.randn(1, 2)\n","\n","y1 = torch.stack((x1, x2), dim=0)\n","y2 = torch.stack((x1, x2), dim=1)\n","y3 = torch.stack((x1, x2), dim=2)\n","\n","print(x1.shape, x2.shape, sep='\\n')\n","print(y1.shape, y2.shape, y3.shape, sep='\\n')\n","\n","print(x1, x2, sep='\\n')\n","print(y1, y2, y3, sep='\\n')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2])\n","torch.Size([1, 2])\n","torch.Size([2, 1, 2])\n","torch.Size([1, 2, 2])\n","torch.Size([1, 2, 2])\n","tensor([[ 0.5468, -0.3392]])\n","tensor([[-0.5758,  0.0322]])\n","tensor([[[ 0.5468, -0.3392]],\n","\n","        [[-0.5758,  0.0322]]])\n","tensor([[[ 0.5468, -0.3392],\n","         [-0.5758,  0.0322]]])\n","tensor([[[ 0.5468, -0.5758],\n","         [-0.3392,  0.0322]]])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ai6AvXAhcEq","executionInfo":{"status":"ok","timestamp":1632499394011,"user_tz":-540,"elapsed":424,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"786713b2-5505-457e-fece-23dec39a5354"},"source":["# vstack\n","x1 = torch.randn(2, 3, 4)\n","x2 = torch.randn(2, 3, 4)\n","\n","y = torch.vstack((x1, x2))\n","print(y.shape) # (4, 3, 4)\n","print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 3, 4])\n","tensor([[[-0.9154, -0.2477, -0.4924,  0.2846],\n","         [-0.4548,  0.8675, -0.6013,  0.2208],\n","         [-1.6972, -3.2085, -0.7774, -0.2032]],\n","\n","        [[-0.6598, -0.3618, -1.3260, -0.2642],\n","         [ 1.3453, -0.3754,  0.0592, -1.4695],\n","         [ 0.4837,  1.4451,  0.1663,  0.0582]],\n","\n","        [[ 0.1270, -0.9210,  0.8833, -2.5603],\n","         [-0.3061, -0.2937, -1.9509, -0.8583],\n","         [-0.9136,  0.4834, -0.2130,  0.0528]],\n","\n","        [[-0.6842,  0.9185,  0.6885,  1.5271],\n","         [-1.5206,  0.0565, -1.7724, -0.4526],\n","         [-0.3464, -0.8440, -1.1350, -1.6760]]])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwnZwD-qi_Pd","executionInfo":{"status":"ok","timestamp":1632499455280,"user_tz":-540,"elapsed":426,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"3e6a3796-4ea1-4bd0-c083-a0f1d42e51e3"},"source":["# hstack\n","x1 = torch.randn(2, 3, 4)\n","x2 = torch.randn(2, 3, 4)\n","\n","y = torch.hstack((x1, x2))\n","print(y.shape) # (2, 6, 4)\n","print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 6, 4])\n","tensor([[[ 1.4115e+00,  1.0316e+00, -1.1565e-01,  8.2927e-01],\n","         [-2.5447e-01,  3.7793e-01, -1.8413e+00, -8.9530e-01],\n","         [ 1.9382e-02,  1.9052e+00, -1.4014e+00, -4.8985e-02],\n","         [ 2.0805e-01, -9.0104e-01, -2.0825e-01,  2.2560e+00],\n","         [-1.0309e+00,  2.7812e-01,  1.3619e-03, -8.4614e-01],\n","         [ 6.3844e-01, -1.2345e+00, -1.2544e+00,  1.4346e+00]],\n","\n","        [[-6.0755e-02,  7.6914e-02,  1.1443e-02,  1.0369e+00],\n","         [ 1.2290e+00,  8.1587e-01, -1.0058e+00, -1.5504e+00],\n","         [ 1.4567e+00,  4.0380e-01, -5.5423e-01,  6.4927e-02],\n","         [-4.9451e-01,  2.5306e-01, -1.7838e+00, -2.9622e-01],\n","         [ 3.1463e-01, -2.9277e-01,  1.0445e+00,  1.9620e-01],\n","         [ 1.8116e-01, -1.5390e-01, -5.0856e-01,  1.7285e-02]]])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ABxoBJ4lcuW","executionInfo":{"status":"ok","timestamp":1632500058698,"user_tz":-540,"elapsed":373,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"dc0a9751-daaa-402a-b141-f208d017d6a7"},"source":["# dstack\n","x1 = torch.randn(2, 3, 4)\n","x2 = torch.randn(2, 3, 4)\n","\n","y = torch.dstack((x1, x2))\n","print(y.shape) # (2, 3, 8)\n","print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3, 8])\n","tensor([[[-0.5894, -0.1969, -0.0938,  0.4447,  0.7467,  0.0866, -1.6301,\n","           2.2125],\n","         [ 1.3138, -0.9577,  0.4234,  0.9972, -0.3345,  1.8383,  0.3826,\n","           0.6105],\n","         [ 0.3751,  0.0412,  1.0531, -1.7201,  0.7172, -0.9315,  0.0231,\n","          -0.7532]],\n","\n","        [[-0.5059,  0.4501, -1.1764, -1.2726,  0.0491,  0.0243,  0.8455,\n","          -1.0309],\n","         [-0.5638,  2.0161, -0.3661, -0.1592,  0.4538,  2.6832, -0.6364,\n","          -0.1315],\n","         [-0.1368, -2.3042,  2.0819, -1.0028, -1.6497, -0.6272,  0.5644,\n","          -0.1861]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"q7lrYxaz2eSK"},"source":["### split, vsplit, hsplit, dsplit\n","#### split\n","- torch.split(tensor, split_size or selections, dim)\n","- split_size(int)인 경우 split_size 값 만큼의 size 갖는 텐서로 나눈다 (batch size같은 개념)\n","- selections(list)인 경우 selections의 element값 만큼을 split_size로 가진다 -> selections 원소의 합이 split하고자 하는 차원의 값과 같아야 함\n","- (3, 16) -> selections: [1, 5, 10] ok\n","- (3, 16) -> selections: [1, 5, 11] X"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TjE2nc0TmdEd","executionInfo":{"status":"ok","timestamp":1632500930543,"user_tz":-540,"elapsed":382,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"4024efa6-207a-42be-f5e6-d98acf85675d"},"source":["x = torch.randn(5, 16)\n","\n","y = torch.split(x, 3, dim=1)\n","for batch in y:\n","    print(batch.shape)\n","\n","print('\\n')\n","\n","z = torch.split(x, [1, 3, 5, 7], dim=1)\n","for batch in z:\n","    print(batch.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 3])\n","torch.Size([5, 3])\n","torch.Size([5, 3])\n","torch.Size([5, 3])\n","torch.Size([5, 3])\n","torch.Size([5, 1])\n","\n","\n","torch.Size([5, 1])\n","torch.Size([5, 3])\n","torch.Size([5, 5])\n","torch.Size([5, 7])\n"]}]},{"cell_type":"markdown","metadata":{"id":"pUyH0CFX3JN3"},"source":["### index_select\n","- torch.index_select(input, dim, index)\n","- index를 통해 특정 index의 tensor를 가져온다\n","- index는 IntTensor 또는 LongTensor type의 1-D tensor이다\n","- input.dim()은 변하지 않는다 (3차원이면 계속 3차원)\n","- input의 dim dimension은 len(index)와 같아진다"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPT-qv1Trz_r","executionInfo":{"status":"ok","timestamp":1632501918001,"user_tz":-540,"elapsed":381,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"91f2deed-11a2-4847-a687-25d5821f3cc4"},"source":["x = torch.randn(3, 4)\n","\n","indices = torch.tensor([0, 2])\n","\n","y = torch.index_select(x, dim=1, index=indices)\n","\n","print(x, y, sep='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.5041, -1.4409,  2.1656,  2.3224],\n","        [-0.9715, -0.7680, -0.8635,  1.2626],\n","        [-0.4589,  0.5104, -0.7188, -1.4460]])\n","tensor([[-0.5041,  2.1656],\n","        [-0.9715, -0.8635],\n","        [-0.4589, -0.7188]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"iF0nLY9q3JJ3"},"source":["### masked_select"]},{"cell_type":"markdown","metadata":{"id":"6odnoFmI3JF9"},"source":["### movedim, moveaxis"]},{"cell_type":"markdown","metadata":{"id":"SrauuXa63JB-"},"source":["### nonzero"]},{"cell_type":"markdown","metadata":{"id":"IMe4k0XD3I-I"},"source":["### reshape\n","- torch.reshape(input, shape)\n","- input과 data는 같다, shape만 다르다\n","- 가능하면 view of input 아니면 copy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QwaPMEuVszrF","executionInfo":{"status":"ok","timestamp":1632502554076,"user_tz":-540,"elapsed":297,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"078e58ca-26d6-4d98-9df8-b3d80fe6e4d8"},"source":["x = torch.arange(4.)\n","\n","y = torch.reshape(x, (2, 2))\n","\n","z = torch.reshape(y, (-1, ))\n","\n","print(y.shape, z.shape)\n","\n","print(y, z, sep='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 2]) torch.Size([4])\n","tensor([[0., 1.],\n","        [2., 3.]])\n","tensor([0., 1., 2., 3.])\n"]}]},{"cell_type":"markdown","metadata":{"id":"y1Cg_OlH6dxJ"},"source":["### ravel\n","- torch.ravel(input)\n","- Return a contiguous flattened tensor. A copy is made only if needed"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THg-bf7R6pMf","executionInfo":{"status":"ok","timestamp":1632539418505,"user_tz":-540,"elapsed":387,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"c5a925ae-8738-41a0-d5ec-319d61b3ad56"},"source":["x = torch.rand(2, 6)\n","\n","y = torch.transpose(x, 0, 1)\n","\n","z = torch.ravel(x)\n","\n","print(y.is_contiguous(), y.shape)\n","print(z.is_contiguous(), z.shape)\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["False torch.Size([6, 2])\n","True torch.Size([12])\n"]}]},{"cell_type":"markdown","metadata":{"id":"w-pCNp1I3fnZ"},"source":["### squeeze, unsqueeze"]},{"cell_type":"markdown","metadata":{"id":"2R_wSEVL3fec"},"source":["### transpose\n","- torch.transpose(input, dim0, dim1)\n","- dim0과 dim1이 바뀐 tensor를 리턴\n","- input과 memory를 **공유**👈"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oC15NzWowJ9F","executionInfo":{"status":"ok","timestamp":1632503095264,"user_tz":-540,"elapsed":314,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"0eacf6f8-1d72-4e18-8d38-3f7a79677de1"},"source":["x = torch.randn(2, 3, 4)\n","\n","y = torch.transpose(x, 0, 2) # (4, 3, 2)\n","\n","print(y.shape)\n","\n","y[2][1][0] = 12345\n","\n","print(y[2][1][0] == x[0][1][2])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 3, 2])\n","tensor(True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"S7T8rL_k3fi8"},"source":["### swapaxes, swapdims\n","- transpose와 같음 -> numpy 자주 사용하는 사람들을 위해"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6gue4WXmxS--","executionInfo":{"status":"ok","timestamp":1632503281234,"user_tz":-540,"elapsed":486,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"fad5a196-eebe-4bdb-e75d-da19e64b5602"},"source":["x = torch.randn(2, 3, 4)\n","\n","y = torch.swapaxes(x, 0, 2) # (4, 3, 2)\n","z = torch.swapdims(x, 0, 2) # (4, 3, 2)\n","\n","print(y.shape)\n","print(z.shape)\n","\n","y[2][1][0] = 12345\n","\n","print(y[2][1][0] == x[0][1][2] == z[2][1][0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 3, 2])\n","torch.Size([4, 3, 2])\n","tensor(True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"1_PKDHoA3faN"},"source":["### where"]},{"cell_type":"markdown","metadata":{"id":"ziJEnBH7dAk4"},"source":["### gather"]},{"cell_type":"markdown","metadata":{"id":"Wz2TW3gKpMax"},"source":["### ❓ view of the original tensor\n","- https://pytorch.org/docs/stable/tensor_view.html"]},{"cell_type":"markdown","metadata":{"id":"blcilSefuScz"},"source":["### ❓ viewing vs copying"]},{"cell_type":"markdown","metadata":{"id":"VFPLCrnGjE1Z"},"source":["- view는 memory를 공유, copy는 memory를 공유X"]},{"cell_type":"markdown","metadata":{"id":"ogLmDKoetQVv"},"source":["### ❓ contiguous\n","- 연속적인 메모리\n","- contiguous한 텐서인지 확인: Tensor.is_contiguous()\n","- contiguous한 텐서 만들고 싶을 때: Tensor.contiguous()\n","- 텐서의 형태를 바꿀 때 인덱스는 바뀌었으나 실제 메모리 상에서는 배열을 바꾸지 않는다 -> 위치 바꾸는 연산이 잦으면 성능을 떨어트리므로\n","- view()같은 연산은 contiguous한 텐서만 지원하므로 Tensor.contiguous()필요\n","- https://titania7777.tistory.com/3\n","- https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107"]},{"cell_type":"markdown","metadata":{"id":"2vErDv0Sjspr"},"source":["### ❓텐서 사이즈를 바꾸는 여러 가지 방법들의 차이\n","- torch.reshape()\n","    - 굉장히 유연하다\n","    - view될 수도, copy될 수도 있다\n","    - contiguous, non-contiguous 텐서 모두 지원\n","- Tensor.view()\n","    - view만 된다\n","    - contiguous한 텐서만 지원 (Tensor.contiguous()사용하면 error걱정 없이 view 사용가능)\n","\n","- if you just want to reshape tensors, use torch.reshape.\n","- if you're also concerned about memory usage, use view\n","\n","- Tensor.clone().view()\n","    - clone를 하면 memory 공유하지 않는 새로운 텐서 생성\n","    - memory 절대 공유하지 않으면서 사이즈 바꾸고 싶을 때는 clone 사용\n","\n","- Tensor.detach().view()\n","    - computation graph에서 추적되지 않는 텐서를 원할 경우"]},{"cell_type":"markdown","metadata":{"id":"ItaQh0Czv-Jw"},"source":["## 4. Random sampling ⭐️"]},{"cell_type":"markdown","metadata":{"id":"97z7uzPu34uz"},"source":["### seed, manual_seed, initial_seed"]},{"cell_type":"markdown","metadata":{"id":"mR0rpIpz34qQ"},"source":["### bermoulli, multinomial, normal, poisson"]},{"cell_type":"markdown","metadata":{"id":"MlYDJLiN34lv"},"source":["### rand, rand_like"]},{"cell_type":"markdown","metadata":{"id":"A-LuPzTx34g4"},"source":["### randint, randint_like"]},{"cell_type":"markdown","metadata":{"id":"h_O2Kn7934cj"},"source":["### randn, randn_like"]},{"cell_type":"markdown","metadata":{"id":"nIZcstrL4NIh"},"source":["### randperm"]},{"cell_type":"markdown","metadata":{"id":"9iWx7jQNv-G1"},"source":["## 5.Serialization (Save & Load) ⭐️"]},{"cell_type":"markdown","metadata":{"id":"UCvNK5oC4Vau"},"source":["### save, load"]},{"cell_type":"markdown","metadata":{"id":"nK5V_gIEv-Dp"},"source":["## 6. Parallelism ( parallelism on CPU)"]},{"cell_type":"markdown","metadata":{"id":"jJcSRJS25VQm"},"source":["### get_num_threads"]},{"cell_type":"markdown","metadata":{"id":"An-xKmrR5VKj"},"source":["### set_num_threads"]},{"cell_type":"markdown","metadata":{"id":"nkHr3Fc_v96R"},"source":["## 7. Locally disabling gradient computation"]},{"cell_type":"markdown","metadata":{"id":"FbuXLxRA4pGU"},"source":["### no_grad"]},{"cell_type":"markdown","metadata":{"id":"ckPTel6S4pBY"},"source":["### enable_grad"]},{"cell_type":"markdown","metadata":{"id":"X_fmfqRB424_"},"source":["### set_grad_enabled"]},{"cell_type":"markdown","metadata":{"id":"zp5SuB7U5AYS"},"source":["### is_grad_enabled"]},{"cell_type":"markdown","metadata":{"id":"RPPman6A4o8U"},"source":["### inference_mode"]},{"cell_type":"markdown","metadata":{"id":"xYKVC-zx4o3g"},"source":["### is_inference_mode_enabled"]},{"cell_type":"markdown","metadata":{"id":"ylCO7zXLv9vb"},"source":["## 8. Math operations\n","- Pointwise Ops\n","- Reduction Ops\n","- Comparison Ops\n","- Spectral Ops\n","- Other Ops"]},{"cell_type":"markdown","metadata":{"id":"HqSTLQTuwV6g"},"source":["## Pointwise Ops ⭐️"]},{"cell_type":"markdown","metadata":{"id":"p4fK6owa5v3V"},"source":["### add, sub, mul, div, remainder"]},{"cell_type":"markdown","metadata":{"id":"ySLmYx7t5vyh"},"source":["### ceil, floor, round"]},{"cell_type":"markdown","metadata":{"id":"JEF1PV9H5vtG"},"source":["### clip, trunc"]},{"cell_type":"markdown","metadata":{"id":"BU-xs2jm5vn5"},"source":["### cos, sin, sign, sigmoid"]},{"cell_type":"markdown","metadata":{"id":"8z1PEjgy5viV"},"source":["### pow, sqrt, rsqrt"]},{"cell_type":"markdown","metadata":{"id":"V8m0FN2b5vct"},"source":["### imag, real, conj, abs"]},{"cell_type":"markdown","metadata":{"id":"u8MuVF5U7uAm"},"source":["### gradient"]},{"cell_type":"markdown","metadata":{"id":"kkTuN8TF7guu"},"source":["### log, exp"]},{"cell_type":"markdown","metadata":{"id":"UGNyXAG08Qzs"},"source":["## Reduction Ops ⭐️\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RMyys2uj8eZc"},"source":["### max, min"]},{"cell_type":"markdown","metadata":{"id":"CxRT0CcA-OVJ"},"source":["### argmax, argmin"]},{"cell_type":"markdown","metadata":{"id":"FG5ToESr8eTR"},"source":["### all, any"]},{"cell_type":"markdown","metadata":{"id":"sV31ng3p8eHg"},"source":["### mean, median, sum, prod"]},{"cell_type":"markdown","metadata":{"id":"1er0aa9d8eBx"},"source":["### mode"]},{"cell_type":"markdown","metadata":{"id":"G1et-iNs8d73"},"source":["### norm"]},{"cell_type":"markdown","metadata":{"id":"0-2A4Dn-8d2M"},"source":["### unique"]},{"cell_type":"markdown","metadata":{"id":"-cNnPKCp8dwC"},"source":["### count_nonzero"]},{"cell_type":"markdown","metadata":{"id":"h6VMo2W-8dkI"},"source":["## Comparison Ops ⭐️"]},{"cell_type":"markdown","metadata":{"id":"xSIrVNTh-fkW"},"source":["### argsort, kthvalue, srt, topk, msort"]},{"cell_type":"markdown","metadata":{"id":"W9YQ4uzS-3jx"},"source":["### eq, ge, gt"]},{"cell_type":"markdown","metadata":{"id":"RD4Pdo2d-3d7"},"source":["### isclose, isfinite, isinf, isnan, isreal"]},{"cell_type":"markdown","metadata":{"id":"ApISLivT-3Xx"},"source":["### maximum, minimum"]},{"cell_type":"markdown","metadata":{"id":"1rePPn5h-3SN"},"source":["### sort, argsort, ,sork"]},{"cell_type":"markdown","metadata":{"id":"v6vKliEx8dd3"},"source":["### kthvalue, topk"]},{"cell_type":"markdown","metadata":{"id":"0FEKDcZJ_ccX"},"source":["## Spectral Ops"]},{"cell_type":"markdown","metadata":{"id":"7qTYaz7c_cV1"},"source":["### stft, istft"]},{"cell_type":"markdown","metadata":{"id":"AcBDrW6i_cPG"},"source":["### hamming_window, hann_window, kaiser_window"]},{"cell_type":"markdown","metadata":{"id":"zN0MGS2s_cIN"},"source":["## Other Ops"]},{"cell_type":"markdown","metadata":{"id":"MCu355Bt_tSL"},"source":["### clone\n","- torch.clone(input)\n","- input의 copy 리턴"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jGBr9LEmVI9","executionInfo":{"status":"ok","timestamp":1632517177845,"user_tz":-540,"elapsed":353,"user":{"displayName":"JaeYeong Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00938800364689824387"}},"outputId":"610a147f-d9d5-4925-d1f0-ae6390a806c2"},"source":["x = torch.rand(2, 3, requires_grad=True)\n","\n","y = torch.clone(x)\n","\n","z = torch.detach(x)\n","\n","print(x, y, z, sep='\\n')\n","\n","print(y.requires_grad)\n","print(z.requires_grad)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1392, 0.3353, 0.9397],\n","        [0.8237, 0.1135, 0.7326]], requires_grad=True)\n","tensor([[0.1392, 0.3353, 0.9397],\n","        [0.8237, 0.1135, 0.7326]], grad_fn=<CloneBackward>)\n","tensor([[0.1392, 0.3353, 0.9397],\n","        [0.8237, 0.1135, 0.7326]])\n","True\n","False\n"]}]},{"cell_type":"markdown","metadata":{"id":"FRVKu5d6_tLj"},"source":["### cumprod, cumsum"]},{"cell_type":"markdown","metadata":{"id":"4_nZH9Tz_tEa"},"source":["### diag, diagonal"]},{"cell_type":"markdown","metadata":{"id":"8elTEBAXAdWr"},"source":["### trace"]},{"cell_type":"markdown","metadata":{"id":"mZ-K5GoH_s9v"},"source":["### diff"]},{"cell_type":"markdown","metadata":{"id":"HhLFTmSK_s3Q"},"source":["### einsum"]},{"cell_type":"markdown","metadata":{"id":"dyo7DeLsAYnN"},"source":["### flatten"]},{"cell_type":"markdown","metadata":{"id":"R-CiBFJKAfom"},"source":["### flip"]},{"cell_type":"markdown","metadata":{"id":"QLHrDNbMAYaP"},"source":["### combinations"]},{"cell_type":"markdown","metadata":{"id":"sFoSUfhGAtT1"},"source":["## BLAS and LAPACK Ops"]},{"cell_type":"markdown","metadata":{"id":"oeW5GBYxA378"},"source":["### addbmm, addmm, bmm"]},{"cell_type":"markdown","metadata":{"id":"cl03TFDfBajC"},"source":["### matmul, mm"]},{"cell_type":"markdown","metadata":{"id":"cI3cqrmABaXQ"},"source":["### dot, inner"]},{"cell_type":"markdown","metadata":{"id":"u4P0I16OBaPj"},"source":["### eig"]},{"cell_type":"markdown","metadata":{"id":"rLGtqz4tBm31"},"source":["### inverse"]},{"cell_type":"markdown","metadata":{"id":"FsCWh3gcBmt7"},"source":["### lstsq"]}]}